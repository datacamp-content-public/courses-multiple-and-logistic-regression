---
title: Insert title here
key: e2eaa8253f6beb165d878ed1a596c863

---
## Fitting a line to a binary response

```yaml
type: "TitleSlide"
key: "d8fd5a3b62"
```

`@lower_third`

name: Joseph Ambrose Pagaran
title: Chief R&D, Ambrosio Bing Computing


`@script`
When analysing a continuous response variable such as a person’s weight or annual income, we would normally use a simple linear regression model to explore possible relationships with other explanatory variables. But what if the response variable is binary or categorical such as win or loss, pass or fail, acceptance or rejection, survival or death. In this screencast, we go ahead in the usual manner of fitting a line to a binary response variable, see what could go wrong, and recommend a rule of thumb.


---
## Wolf spider data

```yaml
type: "TwoColumns"
key: "e3bfe3bd7a"
center_content: false
```

`@part1`
![](https://assets.datacamp.com/production/repositories/4182/datasets/7084f59bdd9d59b724d77d2f8b37e5aa22916ffa/dc-ws.jpg)

Reference:
Suzuki, S., et al., (2006). Acta Arachnologica 55: 79-86.
Source: http://www.utsc.utoronto.ca/~butler/d29/spiders.txt


`@part2`
```python
import pandas as pd
df=pd.read_csv('spiders.txt',sep=';')  

list(df.columns.values) 
```
['Grain size (mm)', 'Spiders']


`@script`
Our response variable is whether a Wolfsipder is absent or present. A picture on the left shows a wolf spider coming out of its own burrows, and below the picture is a summary text describing the wolf spider's behavior and a declaration of being an endangered species. This Wolf spider data is from a team of Japanese researchers who in the year 2006 had collected in order to investigate what would cause wolf spiders to be found on a beach. On the right side we shows a Python code on how we would be able to read data stored in the the file using Python's pandas module; here indicating the name of the file and the column separator, which in this case, is a semi-colon. We can use the list command to identify the column header labels, here GrainnSize and Spiders.


---
## Python packages

```yaml
type: "FullSlide"
key: "3028bc775e"
```

`@part1`
- pandas

```python
#for reading data stored in files, binarize values in string format
import pandas as pd
```

- statsmodels

```python
#for linear and logistic regression modelling, obtaining best-fit parameters
import statsmodels.api as sm
import statsmodels.tools as smt
```
- numpy 

```python
#for performing operations on multi-dimensional arrays
import numpy as np
```
- matplotlib and seaborn

```python
#for plotting and visualizations
import matplotlib.pyplot as plt
import seaborn as sns
```


`@script`
For this screencast is about on logistic regression modelling in Python language, the following are the four basic Python packages that we will be using:
* pandas for reading data stored in files
* statsmodels for statistical modelling
* numpy for mathematical operations on arrays
* matplotlib and seaborn for plotting and visualization
Here, we have used the abbreviations pd, sm, np, plt, and sns.


---
## Summer Escapade ...

```yaml
type: "FullSlide"
key: "ada6df5dd2"
center_content: true
disable_transition: true
```

`@part1`
Imagine travelling to Japan one summer

![](https://assets.datacamp.com/production/repositories/4182/datasets/bb7a6eeb74d0f2886ca96db002980ae4cccd9980/dc-beach.jpg)


`@script`
To start, imagine yourself one day during one summer you decided to travel to Japan but you have no particular idea what to do either to visit the sandy beaches to go for swimming and sunbathing or just go for nature conservation.


---
## Either you are the kind of person who love, or

```yaml
type: "TwoColumns"
key: "1fdfb0df9f"
center_content: true
```

`@part1`
... Japanese beaches, 
but are afraid of Wolf spiders that inhabit near the surface! 

![](https://assets.datacamp.com/production/repositories/4182/datasets/92ed1f3b921b656bbad1ae37831dbfa7528669a0/dc-Parley_spidey__frighty_2286-.jpg)


`@part2`
... love nature and want to save Wolf spiders from going extinct.

![](https://assets.datacamp.com/production/repositories/4182/datasets/45c9cc0bb75558ac84447691f6fba774121a09f6/dc-One-Step-to-Save-the-Nature-.jpg)


`@script`
That surely depends entirely if you are the kind of person that either (as shown on the left) love japanese beaches but are just afraid of Wolf spiders that inhabit near the surface, or (as shown on the right) just love nature's biodiversity and you want to give some efforts to save the wolf spiders from going extinct.


---
## A glimpse of the Wolf spider data

```yaml
type: "FullSlide"
key: "b4a0529ddd"
```

`@part1`
```python
import seaborn as sns
ax = sns.boxplot(y='Grain size (mm)',x='Spiders', data=df)
```
![](https://assets.datacamp.com/production/repositories/4182/datasets/4c5da26768f274e6dfa55762457ce23332448ba6/dc-ws-boxplot.png)


`@script`
To get a quick glimpse of the Wolf spider data we use Python'seaborn package here to create a boxplot, which tells the story that spiders seems to be present when the sand grain size tends to be larger. So we would expect to find some kind of useful relationship in the logistic regression. Note that we have reversed the cause and eﬀect here: in the boxplot we are asking “given that the spider is present or absent, how big are the grains of sand?” a question that might be relevnt for nature conservationist like you, whereas the logistic regression is asking “given the size of the grains of sand, how likely is the spider to be present?”  a question important for someone that has fear of spiders.


---
## Preprocessing: binarizing the Wolf spider data

```yaml
type: "TwoColumns"
key: "b14f47db4e"
```

`@part1`
```python


list(df.columns.values) 
```
![](https://assets.datacamp.com/production/repositories/4182/datasets/95a894c11a593cee0270381c472984aa9cf7e5ef/dc-list-df.jpg)
```python
print(df)
```
![](https://assets.datacamp.com/production/repositories/4182/datasets/1c47f9e2daf8c9ed56324533cead752f65f838fc/dc-print-df.png)


`@part2`
```python
# binarize
tempdf = pd.get_dummies(df)
list(tempdf.columns.values)
```
![](https://assets.datacamp.com/production/repositories/4182/datasets/9ff003be250df75809178184fe53c8a803604b68/dc-list-tempdf.jpg)
```python
print(tempdf)
```
![](https://assets.datacamp.com/production/repositories/4182/datasets/73018745a41675739aa394df6af26bc15300e7f1/dc-print-tempdf.png)


`@script`
Before being able to perform further visualisation and analysis, we have to make sure that the entries in our data are all of numeric type. As shown in the left side, the variable spiders originally has either the string value absent or present. By using pandas' get_dummies() function, we can binarize and have 0 or 1 values, depending if we meant that the spiders are absent (right-hand side, first column to the right) or that the spiders are present (second column to the right).


---
## Linear and Logistic Regression I

```yaml
type: "TwoColumns"
key: "99beddfee4"
```

`@part1`
```python
#linear regression
import statsmodels.api as sm
import statsmodels.tools as smt
x=df2['Grain size (mm)']

#by default no constant, 
#so we need to add a constant
X=smt.add_constant(x) 
y=df2['Spiders_present']

linreg = sm.OLS(y,X).fit()
linreg.params
```

![](https://assets.datacamp.com/production/repositories/4182/datasets/746c7a964d231d5f739f813cde46a7e76fd35956/dc-linreg-params.png)


`@part2`
```python
#logisitic regression 





# same X and y as in linreg
#X has a constant 
# and already added to it.

logitreg = sm.Logit(y,X).fit() 
logitreg.params
```
![](https://assets.datacamp.com/production/repositories/4182/datasets/e6e7aa8b239358f3a7fbd2506b497f896b427f76/dc-logitreg-params.png)


`@script`
We can use Python's statsmodel package, the OLS, which stands for ordinary least squares in the case of linear regression modelling (left panel) and the Logit, for logistic regression modelling (right panel). Here, in both cases we have used the same input variables X and y, where in the X variable we have added a constant using statsmodels tools.


---
## What went wrong with fitting a line?

```yaml
type: "TwoColumns"
key: "de7ba02061"
```

`@part1`
```python
import numpy as np

Xd = np.linspace(-3, 3, 300)
yline=0.743160*Xd+0.294517

import matplotlib.pyplot as plt
plt.scatter(x, y)
plt.plot(Xd, ylin)
```
![](https://assets.datacamp.com/production/repositories/4182/datasets/f8fb7e09e1c0b6d67f945725f7de990c5d097536/dc-ws-linreg.png)


`@part2`
```python

def sigmoid(x):
    return 1 / (1 + np.exp(-x))
ylogit=sigmoid(5.121553*Xd-1.647625)


plt.scatter(x, y)
plt.plot(Xd, ylogit)
```
![](https://assets.datacamp.com/production/repositories/4182/datasets/ed9134a2d56df5710a3c5902348e7ad58180005a/dc-ws-logreg.png)


`@script`
From this summary results slide, we can immediately perform a visual check from the predicted values (drawn in blue line). We have obtained non-sense values of probabilities, that is, values of probabilities that are greater than 1, these are obtained after having used linear regression to model a categorical output variable, which is in this case, a binary one; and not a continuous variable. We know that probabilities can only have values between 0 and 1 as perfectly depicted on the plot shown on the right as in the case of logistic regression modelling.


---
## Does a japanese beach with grain size 0.3 inhabit wolf spiders?

```yaml
type: "TwoColumns"
key: "7d55ad6aef"
```

`@part1`
Linear regression
```python
xd=0.3
ylin_pred=0.743160*xd+0.294517
print(ylin_pred)
```

0.517465

Spiders are present!


`@part2`
Logistic regression
```python

ylog_pred=logit(5.121553*xd-1.647625)
print(ylog_pred)
```

0.4722388046916003

Spiders are absent!


`@script`



---
## What would be the fix?

```yaml
type: "FullImageSlide"
key: "82d3eefb15"
center_content: true
disable_transition: false
```

`@part1`
![](https://assets.datacamp.com/production/repositories/4182/datasets/3f56ad0d55db1f15d50aadd707a02181486e600e/dc-linreg-logitreg-plots-06-.jpg)


`@script`
So as a fix we would recommend a rule of thumb whether to pursue the usual linear regression or use the special case on logistic regression in handling categorical variables, here of binary type, depends on the values of probabilities. If they are extremely close to 0 or 1, then go for logistic regression. Otherwise, when they lie between 0.20 and 0.80, then linear and logistic models would work equally well, though the linear model is preferred over logistic as being easy to interpret among the two.


---
## Let's practice!

```yaml
type: "FinalSlide"
key: "2b73ad4264"
```

`@script`


