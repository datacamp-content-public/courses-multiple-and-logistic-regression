---
title: Insert title here
key: e2eaa8253f6beb165d878ed1a596c863

---
## Fitting a line to a binary response

```yaml
type: "TitleSlide"
key: "d8fd5a3b62"
```

`@lower_third`

name: Joseph Ambrose Pagaran
title: Chief R&D, Ambrosio Bing Computing


`@script`
When analysing a continuous response variable such as a person’s weight or annual income, we would normally use a simple linear regression model to explore possible relationships with other explanatory variables. But what if the response variable is binary or categorical such as win or loss, pass or fail, accept or reject, survival or death. In this screencast, we go ahead in the usual manner of fitting a line to a binary response variable, see what could go wrong, and recommend a rule of thumb.


---
## Summer Escapade ...

```yaml
type: "FullSlide"
key: "ada6df5dd2"
center_content: true
disable_transition: true
```

`@part1`
Imagine travelling to Japan one summer

![](https://assets.datacamp.com/production/repositories/4182/datasets/bb7a6eeb74d0f2886ca96db002980ae4cccd9980/dc-beach.jpg)


`@script`
Imagine one day during one summer you decided to travel to Japan but you have no particular idea what to do either to visit the sandy beaches to go for swimming and sunbathing or just for nature conservation.


---
## Either you are the kind of person who love, or

```yaml
type: "TwoColumns"
key: "1fdfb0df9f"
center_content: true
```

`@part1`
... Japanese beaches, 
but are afraid of Wolf spiders that inhabit near the surface! 

![](https://assets.datacamp.com/production/repositories/4182/datasets/92ed1f3b921b656bbad1ae37831dbfa7528669a0/dc-Parley_spidey__frighty_2286-.jpg)


`@part2`
... love nature and want to save Wolf spiders from going extinct.

![](https://assets.datacamp.com/production/repositories/4182/datasets/45c9cc0bb75558ac84447691f6fba774121a09f6/dc-One-Step-to-Save-the-Nature-.jpg)


`@script`
That depends entirely if you are the kind of person that either (as shown on the left) love japanese beaches but are just afraid of Wolf spiders that inhabit near the surface, or (as shown on the right) just love nature and you want give some efforts to save wolf spiders from going extinct.


---
## Wolf spider data

```yaml
type: "TwoColumns"
key: "e3bfe3bd7a"
center_content: false
```

`@part1`
![](https://assets.datacamp.com/production/repositories/4182/datasets/7084f59bdd9d59b724d77d2f8b37e5aa22916ffa/dc-ws.jpg)

Reference:
Suzuki, S., et al., (2006). Acta Arachnologica 55: 79-86.
Source: http://www.utsc.utoronto.ca/~butler/d29/spiders.txt


`@part2`
```python
import pandas as pd
df=pd.read_csv('spiders.txt',sep=';')  

list(df.columns.values) 
```
['Grain size (mm)', 'Spiders']


`@script`
For our own puposes, we will use the Wolf spider data that a team of Japanese researchers in the year 2006 had collected in order to investigate what would cause wolf spiders to be found on a beach. The picture on the left shows the wolf spider coming out of its own burrows, and below the picture is a summary text describing the wolf spider behavior and a declaration of being an endangered species and of having high risk of extinction. The picture on the right shows how to call Python's pandas module


---
## A glimpse of the Wolf spider data

```yaml
type: "FullSlide"
key: "b4a0529ddd"
```

`@part1`
```python
import seaborn as sns
ax = sns.boxplot(y='Grain size (mm)',x='Spiders', data=df)
```
![](https://assets.datacamp.com/production/repositories/4182/datasets/4c5da26768f274e6dfa55762457ce23332448ba6/dc-ws-boxplot.png)


`@script`
Furthermore using Python'sseaborn package we can have a quick glimpse of the Wolf spider data by creating a boxplot, which tells the story that spiders seems to be present when the sand grain size tends to be larger. So we would expect to find some kind of useful relationship in the logistic regression. Note that we have reversed the cause and eﬀect here: in the boxplot we are asking “given that the spider is present or absent, how big are the grains of sand?” a question that might be relevnt for nature conservationist like you, whereas the logistic regression is asking “given the size of the grains of sand, how likely is the spider to be present?”  a question important for someone that has fear of spiders.


---
## Preprocessing: binarizing the Wolf spider data

```yaml
type: "TwoColumns"
key: "b14f47db4e"
```

`@part1`
```python


list(df.columns.values) 
```
![](https://assets.datacamp.com/production/repositories/4182/datasets/95a894c11a593cee0270381c472984aa9cf7e5ef/dc-list-df.jpg)
```python


print(df)
```


`@part2`
```python
# binarize
tempdf = pd.get_dummies(df)
list(tempdf.columns.values)
```
['Grain size (mm)', 'Spiders_absent', 'Spiders_present']
```python
print(tempdf)
```


`@script`



---
## Linear and Logistic Regression plots

```yaml
type: "FullImageSlide"
key: "ad50ba4631"
center_content: true
```

`@part1`
![](https://assets.datacamp.com/production/repositories/4182/datasets/b9204b0517c46419f0c18f32c8dc6c749fd75a07/dc-linreg-logitreg-plots-01-.jpg)


`@script`
After having performed data pre-processing such as converting all entries into numeric type, we can continue to the use the seaborn package to find the best-fit line as shown on the left panel using ordinary-least squares in linear regression and as shown on the right using maximum likelihood in logistic regression framework.


---
## Best-fit Model parameters

```yaml
type: "TwoColumns"
key: "0a93665cac"
center_content: true
```

`@part1`
Ordinary-least squares (OLS)
```
import statsmodels.formula.api as smf
#we can use R style formulas:
linreg = smf.ols('y ~ X',data=df).fit()
linreg.summary()
```
![](https://assets.datacamp.com/production/repositories/4182/datasets/488915129b6c61863ee21dce3ff74d866df1c8f1/dc-ols.jpg)


`@part2`
Maximum-likelihood estimation (MLE)
```


logreg=smf.logit('y ~ X',data=df).fit()
logreg.summary()
```
![](https://assets.datacamp.com/production/repositories/4182/datasets/9ce0b0022246f03dc0b0b0d9f55567a60c3e6e6d/dc-mle.jpg)


`@script`
As Python's seaborn package is only built solely for visualization, we have to use a separate statsmodel package to retrieve the best-fit model parameters such the slope and intercept, which we will write in the next slide.


---
## What went wrong?

```yaml
type: "FullImageSlide"
key: "bfd05e3ec8"
center_content: true
```

`@part1`
![](https://assets.datacamp.com/production/repositories/4182/datasets/a693206f2548af7d807d497047df26db16ecea91/dc-linreg-logitreg-plots-03-.jpg)


`@script`
To put all results in one slide, the best-fit derived equations (top panel), their best-fit plots (middle panel), and predicted values (bottom panels)


---
## What went wrong?

```yaml
type: "FullImageSlide"
key: "a12d69b44a"
center_content: true
disable_transition: true
```

`@part1`
![](https://assets.datacamp.com/production/repositories/4182/datasets/91b99197f2ce6d7a4853b572925f4a65d505bfaf/dc-linreg-logitreg-plots-04-.jpg)


`@script`
From this summary results slide, we can immediately perform a visual check from the predicted values (bottom panel) as well as from the portions of the plot (middle panel left). As highlighted in red rectangle, that we have obtained non-sense values of probabilities, that is, values of probabilities that are greater than 1, these are obtained after having used linear regression to model a categorical output variable, which is in this case, a binary one; and not a continuous variable. We know that probabilities can only have values between 0 and 1 as perfectly depicted on the plot shown on the right as in the case of logistic regression modelling.


---
## What would be the fix?

```yaml
type: "FullImageSlide"
key: "82d3eefb15"
center_content: true
disable_transition: false
```

`@part1`
![](https://assets.datacamp.com/production/repositories/4182/datasets/3f56ad0d55db1f15d50aadd707a02181486e600e/dc-linreg-logitreg-plots-06-.jpg)


`@script`
So as a fix we would recommend a rule of thumb whether to pursue the usual linear regression or use the special case on logistic regression in handling categorical variables, here of binary type, depends on the values of probabilities. If they are extremely close to 0 or 1, then go for logistic regression. Otherwise, when they lie between 0.20 and 0.80, then linear and logistic models would work equally well, though the linear model is preferred over logistic as being easy to interpret among the two.


---
## Let's practice!

```yaml
type: "FinalSlide"
key: "2b73ad4264"
```

`@script`


