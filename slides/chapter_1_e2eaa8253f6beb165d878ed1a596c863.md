---
title: Insert title here
key: e2eaa8253f6beb165d878ed1a596c863

---
## Fitting a line to a binary response

```yaml
type: "TitleSlide"
key: "d8fd5a3b62"
```

`@lower_third`

name: Joseph Ambrose Pagaran
title: Chief R&D, Ambrosio Bing Computing


`@script`
When analysing a continuous response variable such as as a person’s weight or annual income, we would normally use a simple linear regression model to explore possible relationships with other explanatory variables. But what if the response variable is binary or categorical such as win or loss, pass or fail, survival or death. In this video, we go ahead in the usual manner of fitting a line to a binary response variable, see what could go wrong, and fix it using a logit function of logistic regression.


---
## Kinds of discrete output variable

```yaml
type: "FullSlide"
key: "89a8dfbd72"
```

`@part1`
Output variable is usually continuous.

But what if it is discrete?

* **binary output**: _e.g._ yes/no, success/failure, survival/death, admission/rejection; gender 

* ordinal output (ordered): _e.g._ low, medium, high intensity; freshman, sophomore, junior and senior years; 

* nominal output (without order): _e.g._ brown, green, blue eye colors;  marital status


`@script`
Often the response or output variable is not a numerical value or continuous variable. Instead, it is discrete, for example, **binary output**, a designation of one of two possible outcomes; and more than two possible outcomes, depending on whether there is some order, **ordinal output**, and without order,** nominal output**. As our case can easily be extended to more than two possible outcomes, we focus only on binary output.


---
## Summer Escapade ...

```yaml
type: "FullSlide"
key: "ada6df5dd2"
```

`@part1`
Imagine travelling to Japan one summer![](https://assets.datacamp.com/production/repositories/4182/datasets/bb7a6eeb74d0f2886ca96db002980ae4cccd9980/dc-beach.jpg)


`@script`



---
## Either you love

```yaml
type: "TwoColumns"
key: "1fdfb0df9f"
```

`@part1`
... Japanese beaches, 
but are afraid of Wolf spiders! 

![](https://assets.datacamp.com/production/repositories/4182/datasets/92ed1f3b921b656bbad1ae37831dbfa7528669a0/dc-Parley_spidey__frighty_2286-.jpg)


`@part2`
... love nature and want to save Wolf spiders from going extinct.

![](https://assets.datacamp.com/production/repositories/4182/datasets/45c9cc0bb75558ac84447691f6fba774121a09f6/dc-One-Step-to-Save-the-Nature-.jpg)


`@script`



---
## Wolf spider data

```yaml
type: "TwoColumns"
key: "e3bfe3bd7a"
```

`@part1`
![](https://assets.datacamp.com/production/repositories/4182/datasets/7084f59bdd9d59b724d77d2f8b37e5aa22916ffa/dc-ws.jpg)

Reference:
Suzuki, S., et al., (2006). Acta Arachnologica 55: 79-86.
Source: http://www.utsc.utoronto.ca/~butler/d29/spiders.txt


`@part2`
![](https://assets.datacamp.com/production/repositories/4182/datasets/539dc253d83f89d115b2ffcbec258cbeec91d5c0/dc-ws-map.jpg)


`@script`
A team of Japanese researchers were investigating what would cause the burrowing wolf spider Lycosa ishikariana to be found on a beach. They hypothesized that it had to do with the size of the grains of sand on the beach. They went to 28 beaches in Japan, measured the average sand grain size (in millimetres), and observed the presence or absence of this particular spider on each beach. The data are in http://www.utsc.utoronto.ca/~butler/d29/spiders.txt.


---
## Python packages

```yaml
type: "TwoColumns"
key: "0b36ec2144"
```

`@part1`
pandas
```python
# read csv files, use dataframe
import pandas  
# read_csv()
```
sklearn 
```python
# converting array elements 
# from string to numeric types
from sklearn import preprocessing 
# LabelEncoder()
```


`@part2`
statsmodels
```python
# linear regression modelling
import statsmodels.formula.api as smf 
#
#linear and logistic regression
# smf.ols().fit() & smf.logit().fit()
# 
# getting model parameters & values
# summary(), fittedvalues, predict()
```

matplotlib and seaborn 
```python
# visualization
import matplotlib.pyplot as plt #show()
import seaborn as sns 
#
# regression plot
# regplot()
```


`@script`



---
## A glimpse of the Wolf spider data 

```yaml
type: "FullSlide"
key: "1fc4b224b3"
```

`@part1`
```python
import pandas
import seaborn as sns
df = pandas.read_csv('grainsize.csv',sep=';')
ax = sns.boxplot(y='Grain size (mm)', x='Spiders', data=df)
```
![](https://assets.datacamp.com/production/repositories/4182/datasets/da00eeb9085298ac3ef01daa49cda8c778e4b13d/dc-ws-boxplot.png)


`@script`
The story seems to be that when spiders are present, the sand grain size tends to be larger. So
we would expect to ﬁnd some kind of useful relationship in the logistic regression. Note that we have reversed the cause and eﬀect here: in the boxplot we are asking “given that the spider is present or absent, how big are the grains of sand?”, whereas the logistic regression is asking “given the size of the grains of sand, how likely is the spider to be present?”. But if
one variable has to do with the other, we would hope to see the link either way around.


---
## Data preprocessing

```yaml
type: "TwoColumns"
key: "ec35eae5b5"
```

`@part1`
```python
grainsize = df['Grain size (mm)']
spider = df['Spiders']
print(spider)
```
![](https://assets.datacamp.com/production/repositories/4182/datasets/ea9fbceceb795a7bf5fa80c0ef3f9d7a8ce72803/dc-spider-pandas.jpg)


`@part2`
```python
from sklearn import preprocessing as pp
lab_enc = pp.LabelEncoder()
X = grainsize 
y = lab_enc.fit_transform(spider)
print(y)
```
![](https://assets.datacamp.com/production/repositories/4182/datasets/2cbe465d7dc23d7d7709de5f47c9f684fc1f118b/dc-spider-binarized.jpg)


`@script`



---
## Linear Regression plots

```yaml
type: "FullSlide"
key: "4ac3d85f0e"
```

`@part1`
```python
import matplotlib.pyplot as plt
df['Spiders']=y # update dataframe
sns.regplot(x='Grain size (mm)', y='Spiders', data=df)
plt.show()
```
![](https://assets.datacamp.com/production/repositories/4182/datasets/3e5c8ea4a798baa2a6a73732297e1839048a9f64/dc-linreg.png)


`@script`



---
## Logistic Regression plots

```yaml
type: "FullSlide"
key: "b5f7b5560e"
```

`@part1`
```python
sns.regplot(x='Grain size (mm)', y='Spiders', data=df, logistic=True)
plt.show()
```
![](https://assets.datacamp.com/production/repositories/4182/datasets/ba4354e365aa92213c91d61afc91c81246d0fd44/dc-logitreg.png)


`@script`



---
## Best-fit Model parameters

```yaml
type: "TwoColumns"
key: "0a93665cac"
```

`@part1`
Ordinary-least squares (OLS)
```
import statsmodels.formula.api as smf
#we can use R style formulas:
linreg = smf.ols('y ~ X',data=df).fit()
linreg.summary()
```
![](https://assets.datacamp.com/production/repositories/4182/datasets/488915129b6c61863ee21dce3ff74d866df1c8f1/dc-ols.jpg)


`@part2`
Maximum-likelihood estimation (MLE)
```


logreg=smf.logit('y ~ X',data=df).fit()
logreg.summary()
```
![](https://assets.datacamp.com/production/repositories/4182/datasets/9ce0b0022246f03dc0b0b0d9f55567a60c3e6e6d/dc-mle.jpg)


`@script`



---
## Let's practice with Space Shuttle Challenger binary data!

```yaml
type: "FinalSlide"
key: "2b73ad4264"
```

`@script`


