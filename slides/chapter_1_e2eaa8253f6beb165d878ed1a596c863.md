---
title: Insert title here
key: e2eaa8253f6beb165d878ed1a596c863

---
## Fitting a line to a binary response

```yaml
type: "TitleSlide"
key: "d8fd5a3b62"
```

`@lower_third`

name: Joseph Ambrose Pagaran
title: Chief R&D, Ambrosio Bing Computing


`@script`
When analysing a continuous response variable such as a person’s weight or annual income, we would normally use a simple linear regression model to explore possible relationships with other explanatory variables. But what if the response variable is binary or categorical. In this screencast, we go ahead in the usual manner of fitting a line to a binary response variable, see what could go wrong, and fix it using a logit function in the framework of logistic regression.


---
## Kinds of discrete output variable

```yaml
type: "FullSlide"
key: "89a8dfbd72"
center_content: false
```

`@part1`
Output variable is usually continuous.

But what if it is discrete?

* **binary output**: _e.g._ yes/no, success/failure, survival/death, admission/rejection; gender

* ordinal output (ordered): _e.g._ low, medium, high intensity; freshman, sophomore, junior and senior years; 

* nominal output (without order): _e.g._ brown, green, blue eye colors;  marital status


`@script`
Before we start, let me mention the various situations when the response or output variable is not a numerical value or continuous variable. Instead, it is discrete, for example, **binary output**, a designation of one of two possible outcomes; and more than two possible outcomes, depending on whether there is some order, **ordinal output**, and without order,** nominal output**. As our case can easily be extended to more than two possible outcomes, however, we focus at the moment only on simplest case on the binary output.


---
## Summer Escapade ...

```yaml
type: "FullSlide"
key: "ada6df5dd2"
center_content: true
```

`@part1`
Imagine travelling to Japan one summer

![](https://assets.datacamp.com/production/repositories/4182/datasets/bb7a6eeb74d0f2886ca96db002980ae4cccd9980/dc-beach.jpg)


`@script`
Imagine travelling to Japan one summer to visit the sand beaches for swimming and sunbathing.


---
## Either you are the kind of person who love, or

```yaml
type: "TwoColumns"
key: "1fdfb0df9f"
center_content: true
```

`@part1`
... Japanese beaches, 
but are afraid of Wolf spiders that inhabit near the surface! 

![](https://assets.datacamp.com/production/repositories/4182/datasets/92ed1f3b921b656bbad1ae37831dbfa7528669a0/dc-Parley_spidey__frighty_2286-.jpg)


`@part2`
... love nature and want to save Wolf spiders from going extinct.

![](https://assets.datacamp.com/production/repositories/4182/datasets/45c9cc0bb75558ac84447691f6fba774121a09f6/dc-One-Step-to-Save-the-Nature-.jpg)


`@script`
Either you love japanese beaches but are just afraid of Wolf spiders, or you love nature and you want to save wolf spiders from going extinct. Either case, a linear model is needed in order to help you find out if the beach you plan to go to is inhabited by Wolf spiders or not,; or what would be the kind of sand that the Wolf spiders thrive and survive extinction.


---
## Wolf spider data

```yaml
type: "TwoColumns"
key: "e3bfe3bd7a"
center_content: false
```

`@part1`
![](https://assets.datacamp.com/production/repositories/4182/datasets/7084f59bdd9d59b724d77d2f8b37e5aa22916ffa/dc-ws.jpg)

Reference:
Suzuki, S., et al., (2006). Acta Arachnologica 55: 79-86.
Source: http://www.utsc.utoronto.ca/~butler/d29/spiders.txt


`@part2`
![](https://assets.datacamp.com/production/repositories/4182/datasets/539dc253d83f89d115b2ffcbec258cbeec91d5c0/dc-ws-map.jpg)


`@script`
Lucky you, the job has already been half done! A team of Japanese researchers had investigated what would cause the burrowing wolf spider Lycosa ishikariana to be found on a beach. They hypothesized that it had to do with the size of the grains of sand on the beach. They went to 28 beaches in Japan, measured the average sand grain size (in millimetres), and observed the presence or absence of this particular spider on each beach. The data are in http://www.utsc.utoronto.ca/~butler/d29/spiders.txt.


---
## Python packages

```yaml
type: "TwoColumns"
key: "0b36ec2144"
```

`@part1`
pandas
```python
# read csv files, use dataframe
import pandas  
# read_csv()
```
sklearn 
```python
# converting array elements 
# from string to numeric types
from sklearn import preprocessing 
# LabelEncoder()
```


`@part2`
statsmodels
```python
# linear regression modelling
import statsmodels.formula.api as smf 
#
#linear and logistic regression
# smf.ols().fit() & smf.logit().fit()
# 
# getting model parameters & values
# summary(), fittedvalues, predict()
```

matplotlib and seaborn 
```python
# visualization
import matplotlib.pyplot as plt #show()
import seaborn as sns 
#
# regression plot
# regplot()
```


`@script`
To perform the reading, preprocessing, modeling, and visualisations of the Wolf spider data the following the Python packages will be used in this section. The two packages listed on the left, (pandas and sklearn are) for data-munging and pre-processing. The other two packages on the right, (statsmodel, matplotlib and seaborn are) for regression modeling and visulisation.


---
## A glimpse of the Wolf spider data 

```yaml
type: "FullSlide"
key: "1fc4b224b3"
```

`@part1`
```python
import pandas
import seaborn as sns
df = pandas.read_csv('grainsize.csv',sep=';')
ax = sns.boxplot(y='Grain size (mm)', x='Spiders', data=df)
```
![](https://assets.datacamp.com/production/repositories/4182/datasets/da00eeb9085298ac3ef01daa49cda8c778e4b13d/dc-ws-boxplot.png)


`@script`
Let us proceed and we can call the pandas package to have a quick glimpse of the Wolf spider data.  The boxplot tells the story that seems to be when spiders are present, the sand grain size tends to be larger. So we would expect to ﬁnd some kind of useful relationship in the logistic regression. Note that we have reversed the cause and eﬀect here: in the boxplot we are asking “given that the spider is present or absent, how big are the grains of sand?”, whereas the logistic regression is asking “given the size of the grains of sand, how likely is the spider to be present?”. But if one variable has to do with the other, we would hope to see the link either way around.


---
## Data preprocessing

```yaml
type: "TwoColumns"
key: "ec35eae5b5"
center_content: true
```

`@part1`
```python
grainsize = df['Grain size (mm)']
spider = df['Spiders']
print(spider)
```
![](https://assets.datacamp.com/production/repositories/4182/datasets/ea9fbceceb795a7bf5fa80c0ef3f9d7a8ce72803/dc-spider-pandas.jpg)


`@part2`
```python
from sklearn import preprocessing as pp
lab_enc = pp.LabelEncoder()
X = grainsize 
y = lab_enc.fit_transform(spider)
print(y)
```
![](https://assets.datacamp.com/production/repositories/4182/datasets/2cbe465d7dc23d7d7709de5f47c9f684fc1f118b/dc-spider-binarized.jpg)


`@script`
To avoid errors in handling strings, we need to convert all string type occurrences in our Wolf spider data to numeric types here using sklearn label encoder; which does nothing but turning to 0 and 1.


---
## Linear and Logistic Regression plots

```yaml
type: "FullImageSlide"
key: "ad50ba4631"
center_content: true
```

`@part1`
![](https://assets.datacamp.com/production/repositories/4182/datasets/b9204b0517c46419f0c18f32c8dc6c749fd75a07/dc-linreg-logitreg-plots-01-.jpg)


`@script`
After having converted all entries into numeric type, we can directly use seaborn package to find the best fit line on the left panel using ordinary-least squares in linear regression and on the right using maximum likelihood in logistic regression framework.


---
## Best-fit Model parameters

```yaml
type: "TwoColumns"
key: "0a93665cac"
center_content: true
```

`@part1`
Ordinary-least squares (OLS)
```
import statsmodels.formula.api as smf
#we can use R style formulas:
linreg = smf.ols('y ~ X',data=df).fit()
linreg.summary()
```
![](https://assets.datacamp.com/production/repositories/4182/datasets/488915129b6c61863ee21dce3ff74d866df1c8f1/dc-ols.jpg)


`@part2`
Maximum-likelihood estimation (MLE)
```


logreg=smf.logit('y ~ X',data=df).fit()
logreg.summary()
```
![](https://assets.datacamp.com/production/repositories/4182/datasets/9ce0b0022246f03dc0b0b0d9f55567a60c3e6e6d/dc-mle.jpg)


`@script`
As seaborn is only a visualization package, we have to use a separate statsmodel package to retrieve the best-fit model parameters, the slope and intercept, as well as the significance in the relationship between explanatory and output variables, and the usual goodness of fit and analysis of variance.


---
## Linear and Logistic Regression plots

```yaml
type: "FullImageSlide"
key: "3122140be1"
center_content: true
```

`@part1`
![](https://assets.datacamp.com/production/repositories/4182/datasets/10bcb08a919cc57402558e8b7e1075dc48335554/dc-linreg-logitreg-plots-02-.jpg)


`@script`
and from statsmodel we can also obtain the predicted values from the best-fit models as provided in the bottom panels.


---
## What went wrong?

```yaml
type: "FullImageSlide"
key: "bfd05e3ec8"
center_content: true
```

`@part1`
![](https://assets.datacamp.com/production/repositories/4182/datasets/a693206f2548af7d807d497047df26db16ecea91/dc-linreg-logitreg-plots-03-.jpg)


`@script`
To put all in one slide, the best-fit derived equations (top panel), their best-fit plots (middle panel), and predicted values (bottom panels)


---
## What went wrong?

```yaml
type: "FullImageSlide"
key: "a12d69b44a"
center_content: true
disable_transition: true
```

`@part1`
![](https://assets.datacamp.com/production/repositories/4182/datasets/91b99197f2ce6d7a4853b572925f4a65d505bfaf/dc-linreg-logitreg-plots-04-.jpg)


`@script`
we can immediately perform a visual check from the predicted values as well as portions of the plot. As highlighted in red rectangle, we obtain non-sense values of probabilities, that is, greater than 1, after having used linear regression to model a categorical output variable, which is in this case, a binary one; the chances of finding or not finding a Wolf spider based on the grain size of sand found in a japanese beach.


---
## What would be the fix?

```yaml
type: "FullImageSlide"
key: "8cc0699992"
center_content: true
```

`@part1`
![](https://assets.datacamp.com/production/repositories/4182/datasets/d01936e64fbbe5bfdb0ee68217d557dd151ab5cd/dc-linreg-logitreg-plots-05-.jpg)


`@script`
The fix would be to use the logit function, such that whenever the predicted value is higher than 0.5, this is rounded to 1 (for our case, a spider is present) and inversely when the value is less than 0.5, this is rounded to 0 (for our case, a spider is absent).


---
## What would be the fix?

```yaml
type: "FullImageSlide"
key: "82d3eefb15"
center_content: true
disable_transition: false
```

`@part1`
![](https://assets.datacamp.com/production/repositories/4182/datasets/3f56ad0d55db1f15d50aadd707a02181486e600e/dc-linreg-logitreg-plots-06-.jpg)


`@script`
Furthermore, as a rule of thumb whether to pursue the usual linear regression or the special case on logistic regression in handling categorical variables, either binary (or ordinal and nominal outcomes), depends on the values of probabilities. If they are extremely close to 0 or 1, then go for logistic regression. Otherwise, when the values of probabilities lie between 0.20 and 0.80 linear and logistic models would work equally well, though the linear model is preferred over logistic as being easy to interpret among the two.


---
## Let's practice with NASA's Space Shuttle Challenger data!

```yaml
type: "FinalSlide"
key: "2b73ad4264"
```

`@script`


